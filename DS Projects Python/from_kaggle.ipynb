{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header = None)\n",
    "test_set = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',\n",
    "                      skiprows = 1, header = None) # Make sure to skip a row for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                  1       2           3   4                    5   \\\n",
      "0  39          State-gov   77516   Bachelors  13        Never-married   \n",
      "1  50   Self-emp-not-inc   83311   Bachelors  13   Married-civ-spouse   \n",
      "2  38            Private  215646     HS-grad   9             Divorced   \n",
      "3  53            Private  234721        11th   7   Married-civ-spouse   \n",
      "4  28            Private  338409   Bachelors  13   Married-civ-spouse   \n",
      "\n",
      "                   6               7       8        9     10  11  12  \\\n",
      "0        Adm-clerical   Not-in-family   White     Male  2174   0  40   \n",
      "1     Exec-managerial         Husband   White     Male     0   0  13   \n",
      "2   Handlers-cleaners   Not-in-family   White     Male     0   0  40   \n",
      "3   Handlers-cleaners         Husband   Black     Male     0   0  40   \n",
      "4      Prof-specialty            Wife   Black   Female     0   0  40   \n",
      "\n",
      "               13      14  \n",
      "0   United-States   <=50K  \n",
      "1   United-States   <=50K  \n",
      "2   United-States   <=50K  \n",
      "3   United-States   <=50K  \n",
      "4            Cuba   <=50K  \n",
      "   0           1       2              3   4                    5   \\\n",
      "0  25     Private  226802           11th   7        Never-married   \n",
      "1  38     Private   89814        HS-grad   9   Married-civ-spouse   \n",
      "2  28   Local-gov  336951     Assoc-acdm  12   Married-civ-spouse   \n",
      "3  44     Private  160323   Some-college  10   Married-civ-spouse   \n",
      "4  18           ?  103497   Some-college  10        Never-married   \n",
      "\n",
      "                   6           7       8        9     10  11  12  \\\n",
      "0   Machine-op-inspct   Own-child   Black     Male     0   0  40   \n",
      "1     Farming-fishing     Husband   White     Male     0   0  50   \n",
      "2     Protective-serv     Husband   White     Male     0   0  40   \n",
      "3   Machine-op-inspct     Husband   Black     Male  7688   0  40   \n",
      "4                   ?   Own-child   White   Female     0   0  30   \n",
      "\n",
      "               13       14  \n",
      "0   United-States   <=50K.  \n",
      "1   United-States   <=50K.  \n",
      "2   United-States    >50K.  \n",
      "3   United-States    >50K.  \n",
      "4   United-States   <=50K.  \n"
     ]
    }
   ],
   "source": [
    "print(train_set.head())\n",
    "print(test_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice a few problems immediately:\n",
    "\n",
    "We don't have a column header for our data\n",
    "There seem to be some unknown values in the fifth row of the test set (the question marks) we need to deal with\n",
    "The target values have periods at the end in the test set but do not in the training set (<=50K. vs. <=50K)\n",
    "Based on the accompanying dataset description, we can see the column names. Let's put those in for our train and test first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "wage_class        32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16281 entries, 0 to 16280\n",
      "Data columns (total 15 columns):\n",
      "age               16281 non-null int64\n",
      "workclass         16281 non-null object\n",
      "fnlwgt            16281 non-null int64\n",
      "education         16281 non-null object\n",
      "education_num     16281 non-null int64\n",
      "marital_status    16281 non-null object\n",
      "occupation        16281 non-null object\n",
      "relationship      16281 non-null object\n",
      "race              16281 non-null object\n",
      "sex               16281 non-null object\n",
      "capital_gain      16281 non-null int64\n",
      "capital_loss      16281 non-null int64\n",
      "hours_per_week    16281 non-null int64\n",
      "native_country    16281 non-null object\n",
      "wage_class        16281 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 1.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_set.info())\n",
    "print(test_set.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.replace(' ?', np.nan).dropna().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.replace(' ?', np.nan).dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nomissing = train_set.replace(' ?', np.nan).dropna()\n",
    "test_nomissing = test_set.replace(' ?', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nomissing['wage_class'] = test_nomissing.wage_class.replace({' <=50K.': ' <=50K', ' >50K.':' >50K'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nomissing.wage_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nomissing.wage_class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Ordinal Encoding to Categoricals\n",
    "\n",
    "Our next step is to use ordinal encoding for the features with a string category since XGBoost (like all of the other machine learning algorithms in Python) requires every feature vector to include only digits. To do this properly, however, we will need to join the two together and apply our encoding so that the same categories exist in both datasets when we do train/test evalulation. There is some debate as to whether you are technically supposed to use one-hot encoding for categorical features (since there isn't supposed to be any inherent ordering) but I found this discussion on the subject interesting. It seems that one-hot encoding isn't necessary for tree-based algorithms, but you may run into a problem using this on linear models. I personally find ordinal encoding is more than sufficient and it significantly reduces your memory footprint if you have quite a few categorical features.\n",
    "\n",
    "First, combine them together into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = pd.concat([train_nomissing, test_nomissing], axis = 0) # Stacks them vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45222 entries, 0 to 16280\n",
      "Data columns (total 15 columns):\n",
      "age               45222 non-null int64\n",
      "workclass         45222 non-null object\n",
      "fnlwgt            45222 non-null int64\n",
      "education         45222 non-null object\n",
      "education_num     45222 non-null int64\n",
      "marital_status    45222 non-null object\n",
      "occupation        45222 non-null object\n",
      "relationship      45222 non-null object\n",
      "race              45222 non-null object\n",
      "sex               45222 non-null object\n",
      "capital_gain      45222 non-null int64\n",
      "capital_loss      45222 non-null int64\n",
      "hours_per_week    45222 non-null int64\n",
      "native_country    45222 non-null object\n",
      "wage_class        45222 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, if the feature is not already numerical, we need to encode it as one. We can use pandas Categorical codes for this task. To make things more simple, I will use a loop to apply this on every feature that isn't an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in combined_set.columns: # Loop through all columns in the dataframe\n",
    "    if combined_set[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
    "        combined_set[feature] = pd.Categorical(combined_set[feature]).codes # Replace strings with an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45222 entries, 0 to 16280\n",
      "Data columns (total 15 columns):\n",
      "age               45222 non-null int64\n",
      "workclass         45222 non-null int8\n",
      "fnlwgt            45222 non-null int64\n",
      "education         45222 non-null int8\n",
      "education_num     45222 non-null int64\n",
      "marital_status    45222 non-null int8\n",
      "occupation        45222 non-null int8\n",
      "relationship      45222 non-null int8\n",
      "race              45222 non-null int8\n",
      "sex               45222 non-null int8\n",
      "capital_gain      45222 non-null int64\n",
      "capital_loss      45222 non-null int64\n",
      "hours_per_week    45222 non-null int64\n",
      "native_country    45222 non-null int8\n",
      "wage_class        45222 non-null int8\n",
      "dtypes: int64(6), int8(9)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "combined_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have all of our features encoded, we need to split these back into their original train/test sizes. \n",
    "#Since they haven't been shuffled we just need to retrieve the same indices as before.\n",
    "\n",
    "final_train = combined_set[:train_nomissing.shape[0]] # Up to the last initial training set row\n",
    "final_test = combined_set[train_nomissing.shape[0]:] # Past the last initial training set row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Model Setup and Grid Search\n",
    "\n",
    "We still have our target value inside our train and test frames that needs to be separated from the feature vectors we will be feeding into XGBoost. Let's get those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = final_train.pop('wage_class')\n",
    "y_test = final_test.pop('wage_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) \n",
    "# Optimize for accuracy since that is the metric used in the Adult Data Set notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 5, 7], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d0c8cf4b6963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimized_GBM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first hyperparameter combination performed best and we already beat our target of 85.95% accuracy in our cross-validation! Let's try optimizing some other hyperparameters now to see if we can beat a mean of 86.78% accuracy. This time, we will play around with subsampling along with lowering the learning rate to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7,0.8,0.9]}\n",
    "ind_params = {'n_estimators': 1000, 'seed':0, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth': 3, 'min_child_weight': 1}\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "optimized_GBM.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, it doesn't look like we can improve on this. However, we may be able to optimize a little further by utilizing XGBoost's built-in cv which allows early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the CV testing performed earlier, we want to utilize the following parameters:\n",
    "\n",
    "Learning_rate (eta) = 0.1\n",
    "Subsample, colsample_bytree = 0.8\n",
    "Max_depth = 3\n",
    "Min_child_weight = 1\n",
    "There are a few other parameters we could tune in theory to squeeze out further performance, but this is a good enough starting point.\n",
    "\n",
    "To increase the performance of XGBoost's speed through many iterations of the training set, and since we are using only XGBoost's API and not sklearn's anymore, we can create a DMatrix. This sorts the data initially to optimize for XGBoost when it builds trees, making the algorithm more efficient. This is especially helpful when you have a very large number of training examples. To create a DMatrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(final_train, y_train) # Create our DMatrix to make XGBoost more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':1} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(final_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_gb.get_fscore()\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdmat = xgb.DMatrix(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = final_gb.predict(testdmat) # Predict using our testdmat\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred > 0.5] = 1\n",
    "y_pred[y_pred <= 0.5] = 0\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred, y_test), 1-accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
